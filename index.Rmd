---
title: "EcoConsPreReg"
description: |
  A new article created using the Distill format.
author:
  - name: Elise Gould 
    affiliation: School of BioSciences, University of Melbourne
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    self_contained: false
---
The Abstract must not exceed 350 words and should list the main results and conclusions, using simple, factual, numbered statements:

Point 1: set the context for and purpose of the work;

Point 2: indicate the approach and methods;

Point 3: outline the main results;

Point 4: identify the conclusions and the wider implications.



**Keywords:**


----


## Introduction ##



### Problem ###




Problem: "Conceptual barriers to adopting preregistration, including users from different disciplines feeling that preregistration is not for them" Pu et al. (2019).

   

"Preregistration considered alienating. Researchers who do non-experimental studies expressed a "not for me" sentiment." We have experienced this first-hand by our peers, and even by ourselves, when opening and looking at preregistration templates.

   

Questions about whether preregistration is useful for exploratory work because it 'limits flexibility' --- and moreover, modelling is, by many, considered exploratory.


### Research Aims, and Template Objectives ###




Research Aim: To develop a Template for Ecology and Conservation.

   

Objectives of the Template itself & internal model of preregistration (this will build upon previous work of mine, namely the QRP chapter. See also Pu et al. for the four 'purposes' of preregistration that they identified in their analysis.

----


## Methods ##



### User-centred design approach ###




\*\*About the Approach\*\* 

As Pu et al. (2019) identify, a designer's intention for preregistration and users' purposes for preregistration may be in conflict and undermine the overarching goal of preregistration --- to improve the reliability of scientific findings. In order to bridge this mismatch, we have taken a user-centred design approach to the problem of preregistration. We do this in two ways, by first using a series of structured and collaborative activities in a workshop setting to reflect on our own research experiences in order to capture scientific workflows as they are done in practice. And secondly to, use a real-world research problem as a case-study to test and evaluate the templates for utility and feasibility in practice.

   

The workshop activities aimed to help us:

a) understand how science is done in practice so that we can use this to inform and tailor the preregistration templates to adequately capture key decision-points in the scientific process;

b) understand how science in practice, whether due to logistical, technical feasibility or normative constraints, differs from some idealised practice;

c) identify challenges and roadblocks to the use and uptake of preregistration in among ecologists and conservation scientists, both in academic and applied research contexts; and to

c) Use this knowledge to inform the design of the templates so they meet their intended purpose and are taken up by researchers.

   

\*\*


### Identifying Ecological Modelling Workflows in Practice ###




On the 4^th^ March 2020, we ran a series of structured activities designed to inform the development of two pre-registration templates, one for field-work and sampling design, the other for modelling and data-analysis. We split the activities into two groups, to better focus discussion for each of these templates. All workshop materials and workshop outputs can be found on the OSF component here \<LINK\>.

   

**Activity 1 - Capturing Workflows and Decision Steps**

   

The objective of this activity was to capture critical decision-steps in the design of both field sampling efforts and modelling exercises. This activity was intended to identify key decision-steps in the scientific process that should be included in a preregistration template.  The first part of this activity was done as individuals, where we reflected on our scientific process for a recent or memorable research project. We listed the steps in the workflow from beginning to end. We attempted to document  critical decision-steps in this process that should be present on a preregistration template. By "critical" we mean that without these decision-steps the template would not a) adequately constrain researcher degrees of freedom and b) transparently document the analytic decision-process. 

   

In the second part of this exercise, we came together as a group to collate each of the steps in our personal workflows onto a group workflow template This template was prepared earlier (\<specific OSF link to the document\>), and consisted of several key 'phases' of the scientific process, with decision-steps grouped under each phase. The development of the draft modelling workflow was derived from previous work by Gould et al. *in prep.,* whilst the field sampling workflow was created specifically for this exercise. We sorted and categorised each decision-step as belonging to a particular workflow phase. Next we grouped similar decision-steps that could be included as a single item on a preregistration template. At the end of this process we reviewed the suggested phases on the workflow to assess whether phases needed further discretisation, aggregation, removal, or amendment. 

**Activity 2 - Challenges and Solutions to Preregistration in Ecology**

   

This second activity aimed to identify critical challenges and roadblocks to the implementation and uptake of preregistration in ecology and conservation, as well as their solutions. We conducted two lots of structured discussions, one for each of the field and modelling template groups. Each discussion was structured using a series of pre-prepared questions and talking points informed by recent debates about preregistration in the literature. These talking points were chosen with the aim of identifying problems in the content and or structuring of the phases and decision steps that were collectively identified in activity 1, as well as any conceptual or philosophical issues with preregistration in ecology, conservation, and in particular modelling, that might impact on the template structure, content and procedural implementation of preregistration. 

   

   

Questions included: should we and how can we change the medium of the template and/or archiving platform to accomodate any roadblocks? How could we change the medium of both the template and the archiving platform to accommodate these issues? What procedural and or technical solutions could we implement to address these roadblocks to preregistration? What decision-tools could be used to aid in completing a preregistration? What sort of parsimony should we aim for in terms of the resolution of the templates and therefore their applicability across different methodologies?


### Turning the Workflows into Preregistration Templates ###




All workshop outputs can be found here (\<Link to Workshop Outputs OSF repository\>). 

   

After the workshop, data sheets from activity 1 were collated and coded using atlas.TI. 

   

The point of this activity is to build on the suggested workflows for both fieldwork and modelling to provide structure and content to the preregistration templates.

   

At the end of this exercise we expect to:

   

Have a complete draft workflow for both fieldwork and modelling and data-analysis that will form the basis of the final preregistration templates.

   

Part I: Identify Scientific Workflows for ecological modelling, both real/in-practice and idealised.

   

Objective: Identify common workflow.

   

Step 1: As a group, reflect on personal experience to identify unique decision-steps. Can a generalised / common workflow across individuals be derived? 

   

Step 2: Search literature to to identify an idealised scientific workflow for ecological modelling research. 

   

Step 3: Code workflows identified in step 1 using codes identified in step 3. Revise common workflow.

   

Part II: Translating Workflows into Preregistration Templates

   

We translated the workflows into the preregistration template by using the following ontology:

   

1\. Decision Phase - each has a "title" and "description" or "definition", steps are grouped under phases. 

2\. Decision Step - each has a "title" and "description" or "definition" choices are grouped into 'steps'. Corresponds to an activity or set of activities in a scientific workflow.

3\. Choices ---\> each 'choice' corresponds to a uniquely numbered item on the PRT requiring a response from user. The style should be in the form of a directive or a question. E.g. "explain how you will do xyzzy". Or "What performance measure will you use for assessing 'goodness of fit'?" In addition, we turned to existing preregistration templates to guide the wording  of some items.


### 'In-situ' Evaluation and Testing of Templates ###




Rather than 'digging back' through the version history of a completed preregistration to ask researchers about the process and how it had been developed in detail, we chose to leverage the version-control and collaborative project management features of GitHub \<cite\> as a tool for documenting both the analytic decisions of the researcher, and for using the preregistration process itself to 'live-develop' the template template. For example, if it turned out that we had missed an important item, or perhaps the phrasing of an item or the order and structure of the template needed to change whilst in the process of completing the preregistration, the suggested change, and its justification would be both recorded in GitHub and linked to an actual preregistration.

   

How we did this using GitHub:

   

Instruction to 

   

(As Pu et al did, they used qualitative interviews to 'walk through the version history of the preregistration, and discuss how it had developed in detail' (p.9) --- we can capture some of that thinking in the moment, by using comments and GitHub issues to capture the reasoning in the moment, as to why a particular decision was made or needs to change. However, I do think we should supplement this process with a structured reflection session. 

   

The reason why tried to capture this as we went, is because "the process of creating preregistration  is difficult to reconstruct with interview questions alone" p16.

**Case Study: Environmental Flows Management**

   

\<TEXT HERE DESCRIBING THE ENVIRONMENTAL FLOWS MANAGEMENT PROBLEM + RESEARCH PROBLEM\>

----


## PRT Conceptual Model and Philosophy underpinning model development ##



### Model Scientific Workflow ###




What model workflow and set of activities does the template presume?

This section describes the 'model scientific workflow' underpinning  the Preregistration Template. 

   

I want to include a figure / diagram here visualising and describing some usual / common or even idealised workflow to accompany both the PRT for

A) PRT users.

B) To Explain the inner conceptual model driving the PRT (as per Pu et al.).

   

*How does this inform the PRT? These broad phases are used to structure the preregistration template.*


### Iterative Model Development & "Living" Preregistrations ###




Paragraph or two describing iterative nature in model development. This was a common theme arising in our discussions and one of the key 'roadblocks' identified.

   

   

*How do we accommodate this structurally and procedurally into the PRT?*

   

*1\. Instruction to PRT users:*

   

"If you find yourself needing to check something with the data before committing to a particular decision about the model or analysis (And you hadn't anticipated needing to perform this check), record:

A) the relevant decision in the template.

B) What do you need to know to move forward?

C) How you will test this? What test or analysis will you perform?

D) What values or outputs of the test or analysis map onto particular decisions (they can be qualitative as well)."

   

I will create a template on GitHub based on the above to be used by Chris + Lyndsey for when this occurs, to be stored on the repository wiki. They can insert this template into the relevant decision step / PRT item and fill out.

   

*2\. "Living" or "Timestamped" or "Adaptive" Preregistrations ---Preregistration in the research process:*

   

See Figure 1 in Pu et al. And [*cos.io/rr*](http://cos.io/rr) - Traditionally the process of preregistration and the 'doing' or execution of the plan is a distinct and sequential process. However, this isn't going to work for modelling (What are the *norms* about the process of modelling - stated that it's iterative. And how does this look in practice --- use our in situ evaluation and testing to capture this.

   

This obviously breaks with the convention of preregistrations as 'static' one-off documents... does it break with this convention so far as to no longer be a 'preregistration'?

   

Pu et al: tendency for preregistrations to go from vague / general to specific over time.

*\<div style="width: 960px; height: 720px; margin: 10px; position: relative;"\>\<iframe allowfullscreen frameborder="0" style="width:960px; height:720px" src="https://app.lucidchart.com/documents/embeddedchart/9c4480bc-8465-4731-83e6-d24d7d2b7818" id="K4J1KZqFLi3u"\>\</iframe\>\</div\>*


### Pu et al. ###




What is the purpose of preregistration? Specifically in modelling.

   

The original purpose of preregistration is "the action of confirming an unalterable version of one's research plan prior to collecting data", such that the act distinguishes preregistered, confirmatory findings from exploratory findings (Nosek et al. 2018 + Kidwell et al. 2016) by way of constraining 'researcher degrees of freedom' or flexibility in both experimental design and data analysis, which has been posited as one of the key reasons contributing to the replication crisis (Ioannidis, 2005, Wagenmakers, 2012).

   

Pu et al. treat preregistration as a user-centred design problem to ask whether it achieves its proposed goals *in practice*, and how the process might be improved. They ask whether the current implementation of preregistration in practice, in terms of its design of the form, and how the process integrates into research practice and the peer review practice, effectively supports its intended goals. By interviewing academic psychologists, they attempt to characterise current understanding of practice, and both the norms and purposes for preregistration that actual users have. The key findings are:

\- Norms around how people use preregistration are uncertain, and vary among users

\- different users have "different purposes for adopting preregistration, and these differ from the original purpose of distinguishing exploratory and confirmatory findings"

\- Depending on what role you assume, there are different 'use-cases' for authors, reviewers/editors. BUT, these different use cases are not explicitly designed for.

\- There are "conceptual barriers to adopting preregistration, including users from different disciplines feeling that preregistration is not for them"

   

Pu et al found that because different users ascribed different purposes to preregistration, it resulted in conflicting designs of preregistration formats, which they argue may ultimately undermine the overarching goal of preregistration: "improving the reliability of scientific findings"

   

   

What do we define as the *purposes* of preregistration, specifically within ecological modelling contexts?

   

\- P**rimary purpose:** "Delimiting flexibility" Following from Pu et al. we define the primary purpose of preregistration for modelling exercises so as to 

   

We take emphasis *off* of the dichotomy of exploratory vs. confirmatory research, because I think these categories are confused and confusing in modelling, and actually unhelpful. Instead I want to focus on delimiting researcher degrees of freedom, so as to reduce the potential for cognitive biases, such as confirmation bias, and the potential for resultant QRPs, such as, cherry-picking, HARKing, etc. etc. Link to my other manuscript.

   

   

\- **Secondary purpose: increasing transparency** \<insert refs to modelling reporting literature - it's dire, can't properly be evaluated by a reviewer, moreover can't be reproduced\> Thus, want to improve the transparency of decision-making and methodology. What is "research transparency" 'Lupia and Elman define *research transparency* to be production transparency (open access data or data collection procedures) and analytic transparency ("a full account of how they draw their analytic conclusions from the data")' --- Lupia and Elman 2014. Pu et al. page 13.

\- **Possibly:** As a way of providing better decision-making to authors. By shifting decision-making to the front. Front-heavy research process. Delays the start of analysis, but results in better decision-making, because the decision-making is more carefully reasoned. But not sure want to set this out as a 'purpose' of the template, or just have this as a section in the reflection towards the end of the manuscript (will depend on how I set up the angle, and the structure of the paper). At the moment, this is my hypothesis, is that it can improve the process, but we'd need to reflect on this. And I think we could do that at the end of the manuscript.

This relates to what Pu et al. found where participants 'felt their research workflow improved by having preregistration as a "forcing function" \[...\] For example, writing down study plans ahead of time might prompt them to think more thoroughly and to anticipate flexibilities / researchers' degree of freedmen advance.' (Page 13). For reviewers 'participant reports that pregistration makes the review process "easier".'

   

   

So what are *our* use-cases?

The shiny-app, allows us to tailor the form firstly to authors and analysts. With help-text, and descriptions of the modelling phase, and step under consideration, as well as definitions and references to supporting resources ---  such as decision-tools for choosing and justifying methodological choices. 

By being able to 'generate a report' - we aim to target reviewers/editors, to allow for a condensed version of the template to be exported. Importantly, Pu et al show that "not all preregistered studies confirm to their preregistrations, or are inconsistent in reporting deviations", thus by making the preregistration available to reviewers, and by providing a platform and method for linking the actual analysis under-taken, we can allow reviewers to properly evaluate the preregistration against the final paper. (AND, must talk back to original aim of bad reporting practices in modelling). Moreover, if you combine formatting changes with our proposed method with GitHub, we hope to tailor the presentation of the completed preregistration + analysis, such that actual analyses and decisions can be linked directly to both files and outcomes.

   

Preregistration *Norms*: 

   

Pu et al.'s working definition of *norms* is 'as a set of ideal behaviours'. A key finding was that norms around both creating and using a preregistration are uncertain. *How will my work address this confusion among researchers about what the norms are, how will it address uncertain norms?*

   

Creating: 

   

\- E.g. what sorts of decisions should be preregistered? Conflicting ideas about whether a power analysis, should for example be included in a preregistration.

   

Using:

\- How to mark the preregistered from the non-preregistered parts of the paper?

\- how to evaluate studies that have used preregistrations and when they should be compared against their preregistration\> This process of "checking" a preregistered study is provisionally defined by Pu et al. as "comparing a manuscript to its preregistration and verifying that the study and the analyses are conducted as the preregistration has specified." Who engages in 'checking' a preregistration? "Authors, reviewers and editors may all engage in checking." *How do we  facilitate checking? And the "checking problem"* "to what detail should or does an author or reviewer / editor check? Pu et al found that the authors engaged in a linear and thorough checking process, but reviewers on editors were not nearly "as exhaustive with checking". How can we facilitate the process? They found that if the "paper is very specific to referring to parts of the preregistration" then this made it easier for reviewers and editors to check. Maybe we could do something else, rather than get the paper to refer to the parts of the preregistration (but I think we should do this with Chris anyway). If we propose the norm of using GitHub to create and check the preregistration., I think this could be a good way of getting around this checking problem. At the very end we have a 'how to box' targeted at authors. And then maybe we have a box targeted at reviewers? Not sure, maybe just focus this paper on authors and the process of creating and using a preregistration.

   

In order to address tis confusion among norms, I state the expected norms that the template has been designed around here. However, I don't expect users to agree on this process. Because we have kept the template in a GitHub repository that can be *forked*, people are free to adapt the template (the items themselves) to suit whatever norm they see fit about how preregistrations should be created and used.

----


## Discussion ##



## talking points ##




*We really didn't know what to expect when we began completing these preregistrations...*

   

*Problems and Challenges in designing preregistration templates*

***TIME***

\- "A natural consequence of increased transparency, is that preregistrations become longer as more possible decisions are made transparent: *increased transparency* implies *increased length*. This trade-off was something we considered important during the design phase, and deciding what was in and out of scope for the preregistration was particularly challenging. Some authors agreed that it did add extra time, but that it was worth it.

\- However, as Pu et al. note, some participants who were both authors and reviewers didn't think that the time-costs of preregistration in research were significantly greater than not preregistering research. Instead they thought of the preregistration process invoking a 'time shift', that brought 'decision points' before data collection instead of during analysis." P.19. In addition, "some reviewers thought that preregistration saves them the time they might have spent wondering about undisclosed flexibilities when working on an un-preregistered paper."

**PURPOSE AND DESIGN IMPLEMENTATION**

\- Competing objectives? Although the purposes of preregistration are not mutually exclusive - as we have decided the purpose of preregistration we have defined here is to both delimit/state flexibility, *and* be flexible. However, "the preference of one purpose over another can have tangible effects on the design of preregistration" p15.

\- **Possibly:** As a way of providing better decision-making to authors. By shifting decision-making to the front. Front-heavy research process. Delays the start of analysis, but results in better decision-making, because the decision-making is more carefully reasoned. But not sure want to set this out as a 'purpose' of the template, or just have this as a section in the reflection towards the end of the manuscript (will depend on how I set up the angle, and the structure of the paper). At the moment, this is my hypothesis, is that it can improve the process, but we'd need to reflect on this. And I think we could do that at the end of the manuscript.

This relates to what Pu et al. found where participants 'felt their research workflow improved by having preregistration as a "forcing function" \[...\] For example, writing down study plans ahead of time might prompt them to think more thoroughly and to anticipate flexibilities / researchers' degree of freedmen advance.' (Page 13). For reviewers 'participant reports that pregistration makes the review process "easier".'
--------------------------
# References